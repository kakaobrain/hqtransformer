dataset:
  dataset: cc15m
  image_resolution: 256
  tokenizer_type: bpe16k_huggingface
  context_length: 64
  bpe_pdrop: 0.1

stage1:
  type: simrqgan2
  embed_dim: 256
  n_embed: 8192
  ema_update: True
  hparams:
    double_z: False
    z_channels: 256
    resolution: 256
    in_channels: 3
    out_ch: 3
    ch: 128
    ch_mult: [1, 2, 4, 4]
    num_res_blocks: 2
    attn_resolutions: [16]
    pdrop: 0.0
    use_init_downsample: True
    use_mid_block: True
    use_attn: True
  hparams_aux:
    shared_codebook: False
    decoding_type: concat
    upsample: pixelshuffle

stage2:
  type: hq-transformer/parallel
  use_cls_cond: False
  use_txt_cond: True
  vocab_size_img: 8192
  weight_bottom: 4.0
  temp_soft_labels: 1.0
  weight_txt: 0.1
  weight_img: 0.9
  hparams:
    embed_dim: 1536
    embedding_type: transformer1
    n_layers: 12
    n_heads: 24
    n_dense_layers: 12
    ctx_len_img: 64
    ctx_len_txt: 64
    embd_pdrop: 0.0
    resid_pdrop: 0.1
    attn_pdrop: 0.0
    mlp_bias: True
    attn_bias: True
    gelu_use_approx: False
    n_classes: 1000

optimizer:
  opt_type: adamW
  base_lr: 0.0003
  weight_decay: 1e-4
  betas: [0.9, 0.95]
  init_lr: 0.00001
  warmup:
      warmup_epoch: 1
      buffer_epoch: 0
      min_lr: 0.0
      mode: fix
      peak_lr: 0.0003
      start_from_zero: True

experiment:
  local_batch_size: 64
  total_batch_size: 512
  epochs: 20
