dataset:
  dataset: imagenet
  image_resolution: 256

stage1:
  type: hqvae
  n_embed: 8192
  ema_update: True
  hparams:
    ch_mult: [1, 2, 4]
    attn_resolutions: [32]
    use_init_downsample: True
    use_mid_block: True
    use_attn: True
  hparams_aux:
    shared_codebook: False
    decoding_type: concat
    upsample: pixelshuffle
    code_levels: 3


stage2:
  type: multilevel-hq
  use_cls_cond: True
  vocab_sizes_img: [8192, 8192, 8192]
  decoding_type: parallel-add
  weight_bottom: 4.0
  hparams:
    embed_dim: 1536
    embedding_type: transformer1
    n_layers: 12
    n_heads: 24
    n_dense_layers: 12
    ctx_len_img: 256
    embd_pdrop: 0.0
    resid_pdrop: 0.1
    attn_pdrop: 0.0
    mlp_bias: True
    attn_bias: True
    gelu_use_approx: False
    n_classes: 1000

optimizer:
  opt_type: adamW
  base_lr: 0.0005
  weight_decay: 1e-4
  betas: [0.9, 0.95]
  init_lr: 0.00001
  warmup:
      warmup_epoch: 1
      buffer_epoch: 0
      min_lr: 0.0
      mode: fix
      peak_lr: 0.0005
      start_from_zero: True

experiment:
  local_batch_size: 16
  total_batch_size: 512
  epochs: 100
